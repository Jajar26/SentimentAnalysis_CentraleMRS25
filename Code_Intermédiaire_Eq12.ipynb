{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkEn0ajQxRQqF9B3C0JjdY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jajar26/SentimentAnalysis_CentraleMRS25/blob/main/Code_Interm%C3%A9diaire_Eq12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki7KFFzcmggE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import requests\n",
        "import time\n",
        "import re\n",
        "from typing import List, Dict\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "XvAguGqkpTxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du dataset\n",
        "df = pd.read_csv(\"investments_VC.csv\", encoding='latin1')"
      ],
      "metadata": {
        "id": "1zpplZFAmnTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "1BimyC6ZnOvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "i1HXF4KYnRSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nettoyage des noms de colonnes\n",
        "df = df.rename(columns={' market ': \"market\", ' funding_total_usd ': \"funding_total_usd\"})"
      ],
      "metadata": {
        "id": "y9XEiQsenTPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition des mots-clés pour isoler le secteur Santé/Pharma\n",
        "pharma_keywords = ['pharma', 'biotech', 'abiotechnology', 'biopharmaceutical',\n",
        "                  'drug', 'therapeutics', 'medicine', 'clinical']\n",
        "\n",
        "mask = pd.Series([False] * len(df))\n",
        "\n",
        "# Recherche dans les catégories et les marchés\n",
        "if 'category_list' in df.columns:\n",
        "    for keyword in pharma_keywords:\n",
        "        mask |= df['category_list'].astype(str).str.lower().str.contains(keyword, na=False)\n",
        "\n",
        "if 'market' in df.columns:\n",
        "    for keyword in pharma_keywords:\n",
        "        mask |= df['market'].astype(str).str.lower().str.contains(keyword, na=False)\n",
        "\n",
        "# Création du sous-ensemble dédié au secteur Pharma\n",
        "pharma_df = df[mask].copy()\n",
        "pharma_df.head()"
      ],
      "metadata": {
        "id": "496tTKAPnVSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre d'entreprises uniques par statut (Opérationnelle, Acquise, Fermée)\n",
        "pharma_df.groupby('status')['name'].nunique()"
      ],
      "metadata": {
        "id": "KMR5Wst7ntSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3840c32c"
      },
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Visualisation de la répartition par statut\n",
        "sns.countplot(data=pharma_df, x='status', palette='viridis', ax=ax, hue='status', legend=False)\n",
        "ax.set_title('Répartition des Statuts (Secteur Pharma)', fontsize=14)\n",
        "ax.set_xlabel('Statut')\n",
        "ax.set_ylabel('Nombre d\\'entreprises')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pharma_df['funding_total_usd'] = (pharma_df['funding_total_usd']\n",
        "                                  .astype(str)\n",
        "                                  .str.strip()\n",
        "                                  .str.replace(',', '', regex=False)\n",
        "                                  .replace('-', np.nan)\n",
        "                                  .replace('', np.nan))\n",
        "\n",
        "\n",
        "pharma_df['funding_total_usd'] = pd.to_numeric(pharma_df['funding_total_usd'], errors='coerce')"
      ],
      "metadata": {
        "id": "xJvq-t3WsSS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features engineering"
      ],
      "metadata": {
        "id": "oGpYnZuap77d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUTOFF = '2012-01-01'\n",
        "FUNDING_TYPES = ['seed', 'venture', 'grant', 'round_A', 'round_B']\n",
        "COLS_NUMERIC = ['age', 'funding_total_usd', 'funding_rounds', 'days_to_first_funding',\n",
        "                'funding_duration', 'funding_velocity', 'round_intensity']\n",
        "FEATURES = COLS_NUMERIC + [f'has_{c}' for c in FUNDING_TYPES] + ['country_code']"
      ],
      "metadata": {
        "id": "SK2nsZdSv5SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_features(df, reference_date, fit_country_encoder=False, rare_countries=None):\n",
        "    d = df.copy()\n",
        "    ref = pd.to_datetime(reference_date)\n",
        "\n",
        "    # Funding_total_usd\n",
        "    d['funding_total_usd'] = pd.to_numeric(d['funding_total_usd'], errors='coerce')\n",
        "    d['funding_total_usd'] = d['funding_total_usd'].fillna(d['funding_total_usd'].median())\n",
        "\n",
        "    # Dates\n",
        "    for col in ['founded_at', 'first_funding_at', 'last_funding_at']:\n",
        "        d[col] = pd.to_datetime(d[col], errors='coerce')\n",
        "\n",
        "    # Âge\n",
        "    d['age'] = ((ref - d['founded_at']).dt.days / 365.25).clip(lower=0.1)\n",
        "\n",
        "    # Durées de financement\n",
        "    d['days_to_first_funding'] = (d['first_funding_at'] - d['founded_at']).dt.days\n",
        "    last_funding_clipped = d['last_funding_at'].clip(upper=ref)\n",
        "    d['funding_duration'] = (last_funding_clipped - d['first_funding_at']).dt.days\n",
        "\n",
        "    # Ratios\n",
        "    d['funding_velocity'] = d['funding_total_usd'] / d['age']\n",
        "    d['round_intensity']  = d['funding_rounds'] / d['age']\n",
        "\n",
        "    for col in FUNDING_TYPES:\n",
        "        d[f'has_{col}'] = (d[col].fillna(0) > 0).astype(int)\n",
        "\n",
        "    for col in COLS_NUMERIC:\n",
        "        d[col] = d.groupby('market')[col].transform(lambda x: x.fillna(x.median()))\n",
        "        d[col] = d[col].fillna(d[col].median())\n",
        "\n",
        "    if fit_country_encoder:\n",
        "        country_counts = d['country_code'].value_counts()\n",
        "        rare_countries  = country_counts[country_counts < 10].index\n",
        "    d['country_code'] = d['country_code'].replace(rare_countries, 'OTHER').fillna('UNKNOWN')\n",
        "\n",
        "    if fit_country_encoder:\n",
        "        return d, rare_countries\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "tLBSIhPKv9Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_raw = pharma_df[\n",
        "    (pd.to_datetime(pharma_df['founded_at']) < CUTOFF) &\n",
        "    (pharma_df['status'] != 'operating')\n",
        "].copy()\n",
        "\n",
        "train_data, rare_countries = build_features(train_raw, CUTOFF, fit_country_encoder=True)\n",
        "\n",
        "train_data['Profitable'] = (train_data['status'].isin(['acquired', 'ipo'])).astype(int)\n",
        "\n",
        "print(f\"Startups d'entraînement : {len(train_data)}\")\n",
        "print(\"\\nÉquilibre des classes :\")\n",
        "print(train_data['Profitable'].value_counts())\n",
        "print(f\"Taux de succès : {train_data['Profitable'].mean():.1%}\")\n",
        "print(f\"\\nPays après regroupement : {train_data['country_code'].nunique()}\")\n",
        "\n",
        "X = pd.get_dummies(train_data[FEATURES], drop_first=True)\n",
        "y = train_data['Profitable']\n",
        "\n",
        "print(f\"\\nFeatures : {X.shape[1]}  |  NaN dans X : {X.isna().sum().sum()}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "X_train_s = scaler_pipeline.fit_transform(X_train)\n",
        "X_test_s  = scaler_pipeline.transform(X_test)"
      ],
      "metadata": {
        "id": "nFQE4ORXwkoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modèle ML"
      ],
      "metadata": {
        "id": "jRY4AJQlpate"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrainement"
      ],
      "metadata": {
        "id": "BH0evv94xbxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": HistGradientBoostingClassifier(class_weight='balanced', max_iter=100, random_state=42),\n",
        "    \"SVM\": SVC(class_weight='balanced', probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    cv_scores = cross_val_score(model, X_train_s, y_train, cv=5, scoring='f1')\n",
        "\n",
        "    model.fit(X_train_s, y_train)\n",
        "    y_pred = model.predict(X_test_s)\n",
        "\n",
        "    results.append({\n",
        "        \"Modele\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred),\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results).sort_values(by=\"F1-Score\", ascending=False)\n",
        "print(\"RÉSULTATS DES MODÈLES\")\n",
        "print(df_results.to_string(index=False))"
      ],
      "metadata": {
        "id": "UpUxQXlCWjvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prédiction"
      ],
      "metadata": {
        "id": "GL7kfySbtgAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scoring_raw = pharma_df[pharma_df['status'] == 'operating'].copy()\n",
        "df_scoring  = build_features(scoring_raw, CUTOFF,\n",
        "                              fit_country_encoder=False,\n",
        "                              rare_countries=rare_countries)\n",
        "\n",
        "X_scoring_raw     = pd.get_dummies(df_scoring[FEATURES], drop_first=True)\n",
        "X_scoring_aligned = X_scoring_raw.reindex(columns=X.columns, fill_value=0).fillna(0)\n",
        "\n",
        "X_scoring_scaled = scaler_pipeline.transform(X_scoring_aligned)\n",
        "\n",
        "# Scores par modèle\n",
        "for name, model in models.items():\n",
        "    df_scoring[f'Score_{name}'] = model.predict_proba(X_scoring_scaled)[:, 1]\n",
        "\n",
        "score_cols = [f'Score_{m}' for m in models]\n",
        "df_scoring['Score_Consensus'] = df_scoring[score_cols].mean(axis=1)\n",
        "\n",
        "# Affichage top 10\n",
        "print(\"TOP 10 DES STARTUPS 'OPERATING' LES PLUS PROMETTEUSES\")\n",
        "cols_display = ['name', 'market', 'Score_Consensus'] + score_cols\n",
        "top_10 = (df_scoring[cols_display]\n",
        "          .sort_values('Score_Consensus', ascending=False)\n",
        "          .head(10))\n",
        "\n",
        "pd.options.display.float_format = '{:.1%}'.format\n",
        "print(top_10.to_string(index=False))\n",
        "\n",
        "output_path = \"startups_scoring.csv\"\n",
        "df_scoring[cols_display].sort_values('Score_Consensus', ascending=False).to_csv(output_path, index=False, float_format='%.4f')"
      ],
      "metadata": {
        "id": "947rRnndv7TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups_scoring = pd.read_csv(\"startups_scoring.csv\", encoding='latin1')"
      ],
      "metadata": {
        "id": "izf5l-po0atX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups_scoring"
      ],
      "metadata": {
        "id": "AAEQQsit0rUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modèle NLP"
      ],
      "metadata": {
        "id": "_Hbw7KseN91e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiSourceEthicalExtractor:\n",
        "    \"\"\"\n",
        "        Sources : ClinicalTrials.gov, PubMed et sites.\n",
        "    \"\"\"\n",
        "\n",
        "    CLINICAL_TRIALS_BASE = \"https://clinicaltrials.gov/api/v2/studies\"\n",
        "    PUBMED_BASE          = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
        "    HEADERS              = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    def search_clinical_trials(self, startup_name: str, max_studies: int = 50) -> List[Dict]:\n",
        "        \"\"\"Recherche les essais cliniques terminés liés à la startup (Sponsor ou Collaborateur).\"\"\"\n",
        "        queries = [\n",
        "            f'AREA[OverallStatus]COMPLETED AND AREA[LeadSponsorName]\"{startup_name}\"',\n",
        "            f'AREA[OverallStatus]COMPLETED AND AREA[CollaboratorName]\"{startup_name}\"',\n",
        "        ]\n",
        "\n",
        "        # Collecte des IDs uniques\n",
        "        nct_ids = list({\n",
        "            nct_id\n",
        "            for q in queries\n",
        "            for nct_id in self._search_nct_ids(q, max_studies)\n",
        "        })\n",
        "        print(f\"[{startup_name}] ClinicalTrials : {len(nct_ids)} essais identifiés\")\n",
        "\n",
        "        return [d for nct_id in nct_ids if (d := self._extract_study_data(nct_id))]\n",
        "\n",
        "    def _search_nct_ids(self, query: str, max_studies: int) -> List[str]:\n",
        "        \"\"\"Méthode interne pour récupérer les identifiants NCT depuis l'API ClinicalTrials.\"\"\"\n",
        "        params = {\"query.term\": query, \"pageSize\": min(max_studies, 1000), \"format\": \"json\"}\n",
        "        try:\n",
        "            r = requests.get(self.CLINICAL_TRIALS_BASE, params=params, timeout=30)\n",
        "            r.raise_for_status()\n",
        "            return [\n",
        "                s['protocolSection']['identificationModule']['nctId']\n",
        "                for s in r.json().get('studies', [])\n",
        "            ]\n",
        "        except Exception:\n",
        "            return []\n",
        "\n",
        "    def _extract_study_data(self, nct_id: str) -> Dict | None:\n",
        "        \"\"\"Récupère les détails textuels (titre, résumé, critères) d'un essai spécifique.\"\"\"\n",
        "        try:\n",
        "            r = requests.get(f\"{self.CLINICAL_TRIALS_BASE}/{nct_id}\",\n",
        "                             params={\"format\": \"json\"}, timeout=30)\n",
        "            s = r.json().get('protocolSection', {})\n",
        "            return {\n",
        "                'source':      'clinicaltrials',\n",
        "                'title':       s.get('identificationModule', {}).get('officialTitle', ''),\n",
        "                'description': s.get('descriptionModule', {}).get('briefSummary', ''),\n",
        "                'eligibility': s.get('eligibilityModule', {}).get('eligibilityCriteria', ''),\n",
        "            }\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def search_pubmed(self, startup_name: str, max_articles: int = 20) -> List[Dict]:\n",
        "        \"\"\"Recherche les publications scientifiques sur PubMed.\"\"\"\n",
        "        try:\n",
        "            # Étape 1 : Recherche des PMIDs\n",
        "            search_r = requests.get(\n",
        "                f\"{self.PUBMED_BASE}/esearch.fcgi\",\n",
        "                params={'db': 'pubmed', 'term': f'\"{startup_name}\"[Affiliation]',\n",
        "                        'retmax': max_articles, 'retmode': 'json'},\n",
        "                timeout=30\n",
        "            )\n",
        "            search_r.raise_for_status()\n",
        "            pmids = search_r.json().get('esearchresult', {}).get('idlist', [])\n",
        "            print(f\"[{startup_name}] PubMed : {len(pmids)} publications trouvées\")\n",
        "\n",
        "            if not pmids:\n",
        "                return []\n",
        "\n",
        "            # Étape 2 : Récupération des résumés (Abstracts)\n",
        "            fetch_r = requests.get(\n",
        "                f\"{self.PUBMED_BASE}/efetch.fcgi\",\n",
        "                params={'db': 'pubmed', 'id': ','.join(pmids), 'retmode': 'xml'},\n",
        "                timeout=30\n",
        "            )\n",
        "            soup = BeautifulSoup(fetch_r.content, 'xml')\n",
        "            articles = []\n",
        "            for article in soup.find_all('PubmedArticle'):\n",
        "                title_tag    = article.find('ArticleTitle')\n",
        "                abstract_tag = article.find('AbstractText')\n",
        "                articles.append({\n",
        "                    'source':      'pubmed',\n",
        "                    'title':       title_tag.text if title_tag else '',\n",
        "                    'description': abstract_tag.text if abstract_tag else '',\n",
        "                    'eligibility': '',\n",
        "                })\n",
        "            time.sleep(0.5)\n",
        "            return articles[:max_articles]\n",
        "        except Exception as e:\n",
        "            print(f\"[{startup_name}] PubMed erreur : {e}\")\n",
        "            return []\n",
        "\n",
        "    def scrape_company_website(self, startup_name: str, website_url: str = None) -> Dict | None:\n",
        "        \"\"\"Scrape les sections relatives à la mission et aux valeurs sur le site web de l'entreprise.\"\"\"\n",
        "        url = website_url or f\"https://{startup_name.lower().replace(' ', '')}.com/about\"\n",
        "        try:\n",
        "            r = requests.get(url, headers=self.HEADERS, timeout=10)\n",
        "            r.raise_for_status()\n",
        "            page_text = BeautifulSoup(r.content, 'html.parser').get_text(separator=' ', strip=True)\n",
        "\n",
        "            # Recherche d'extraits autour des mots-clés de culture d'entreprise\n",
        "            keywords = ['mission', 'values', 'diversity', 'inclusion', 'ethics', 'team', 'culture']\n",
        "            excerpts = [\n",
        "                m\n",
        "                for kw in keywords\n",
        "                for m in re.findall(rf'.{{0,200}}{kw}.{{0,200}}', page_text, re.IGNORECASE)\n",
        "            ]\n",
        "            time.sleep(1)\n",
        "            return {\n",
        "                'source':      'website',\n",
        "                'title':       f\"{startup_name} - Mission & Values\",\n",
        "                'description': ' | '.join(excerpts[:5])[:1000],\n",
        "                'eligibility': '',\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"[{startup_name}] Site web inaccessible : {e}\")\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "v2Pn0ni01cNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nbroad/ESG-BERT\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nbroad/ESG-BERT\")"
      ],
      "metadata": {
        "id": "HJkrxh6CYBBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeuristicESGScorer:\n",
        "    \"\"\"\n",
        "    Scoring éthique via ESG-BERT (nbroad/ESG-BERT).\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_ethical_score(self, all_sources_data):\n",
        "        if not all_sources_data:\n",
        "            return {\n",
        "                'ethical_investment_index': 0.0,\n",
        "                'num_sources': 0,\n",
        "                'data_quality_score': 0.0\n",
        "            }\n",
        "\n",
        "        full_text = \" \".join([\n",
        "            d.get('title', '') + \" \" + d.get('description', '')\n",
        "            for d in all_sources_data\n",
        "        ])\n",
        "\n",
        "        inputs = tokenizer(full_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        probs = torch.softmax(outputs.logits, dim=1).squeeze().tolist()\n",
        "\n",
        "        return {\n",
        "            'ethical_investment_index': round(max(probs), 4),\n",
        "            'num_sources': len(all_sources_data),\n",
        "            'data_quality_score': min(len(all_sources_data) / 30, 1.0)\n",
        "        }"
      ],
      "metadata": {
        "id": "eFuswzMH1WTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ethical_scoring(startup_list: List[Dict], output_file: str = \"ethical_scores.csv\") -> pd.DataFrame:\n",
        "    \"\"\"Scoring pour une liste de startups donnée.\"\"\"\n",
        "    extractor = MultiSourceEthicalExtractor()\n",
        "    scorer    = HeuristicESGScorer()\n",
        "    results   = []\n",
        "\n",
        "    print(f\"Lancement du pipeline pour {len(startup_list)} entreprises\")\n",
        "\n",
        "    for i, startup in enumerate(startup_list, 1):\n",
        "        name    = startup['name']\n",
        "        website = startup.get('website')\n",
        "        print(f\"--- [{i}/{len(startup_list)}] Traitement : {name} ---\")\n",
        "\n",
        "        # Extraction multi-sources\n",
        "        all_data = []\n",
        "        all_data.extend(extractor.search_clinical_trials(name))\n",
        "        all_data.extend(extractor.search_pubmed(name))\n",
        "        if web_data := extractor.scrape_company_website(name, website):\n",
        "            all_data.append(web_data)\n",
        "\n",
        "        # Calcul des scores\n",
        "        scores = scorer.compute_ethical_score(all_data)\n",
        "\n",
        "        results.append({\n",
        "          'startup_name':             name,\n",
        "          'total_sources':            scores['num_sources'],\n",
        "          'ethical_investment_index': scores['ethical_investment_index'],\n",
        "          'data_quality_score':       scores['data_quality_score'],\n",
        "        })\n",
        "\n",
        "        time.sleep(2)  # Respect des limitations d'appels API\n",
        "\n",
        "    # Structuration et sauvegarde\n",
        "    df = pd.DataFrame(results).sort_values('ethical_investment_index', ascending=False)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Opération terminée. Fichier généré : {output_file}\")\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    startups_to_score = [\n",
        "        {'name': 'Zag Bio', 'website': 'https://zagbio.com'},\n",
        "        {'name': 'Azalea Therapeutics', 'website': None},\n",
        "        {'name': 'Braveheart Bio', 'website': None},\n",
        "        {'name': 'Pfizer', 'website': 'https://pfizer.com'},\n",
        "        {'name': 'Moderna', 'website': 'https://modernatx.com'},\n",
        "    ]\n",
        "\n",
        "    df_final = run_ethical_scoring(startups_to_score)"
      ],
      "metadata": {
        "id": "hOFmhcKO1K7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethicals_score = pd.read_csv(\"ethical_scores.csv\", encoding='latin1')"
      ],
      "metadata": {
        "id": "XL0do5SezkmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethicals_score"
      ],
      "metadata": {
        "id": "OpiW7HhP0eAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}